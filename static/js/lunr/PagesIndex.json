[{"title":"How to use CloudBerry Drive with Minio","kbid":1025,"href":"/kb1025","content":" Problem You have Miniohttpsminioio S3 like storage and you want to mount it as disks to your Windows computer Resolution In this short article you will learn how to mount your Minio object storage as disk in Windows Operating system This is useful to share files between people 1 Prerequisites CloudBerry Drivehttpwwwcloudberrylabcomdrive is installed and running Minio Server is running on localhost on port 9000 in HTTP follow Minio quickstart guidehttpsdocsminioiodocsminioquickstartguide to install Minio NOTE You can also run Minio in HTTPS follow this guidehttpsdocsminioiodocsgenerateletsencyptcertificateusingconcertforminio along with CloudBerry Drive 2 Steps Add Minio as storage account in CloudBerry Drive Once CloudBerry Drive installed you can fine out its icon with configuration settings in your tray right bottom corner near clock Fill up the fields accordingly service point your server IP with 8000 9000 port depends your signature version access and secret keys can be obtain from running server console You can activate SSL but your server should be configured accordingly Multipart upload allows to split files into multiple chunks and upload them in multiple threads It is enabled by default CloudBerry Drive for S3 compatibleimagesminiocloudberrydrivestorageminioconfigurationjpg Add drive Now when you have storage account set you can start making drives and map them to your Windows computer even more you can set it as network share and making available across your corporate network Pickup your settings accordingly and hit ok to enable drive CloudBerry Drive options for mapped driveimagesminiocloudberrydrivemappeddrivesettingsjpg Check your mapped drive and start manage your files View your drive and start manage files CloudBerry Drive for Minio view contentimagesminiocloudberrydrivemappeddiskshowcontentjpg 3 Explore Further Minio Client complete guidehttpsdocsminioiodocsminioclientcompleteguide CloudBerry Explorer for Miniohttpwwwcloudberrylabcomexplorer"},{"title":"What is the proper way to submit support case with CloudBerry Lab?","tags":["support"],"kbid":1026,"author":"Eugene","href":"/kb1026","content":"CloudBerry Lab tools are very reliable and mature but in some cases you may meet small issues where CloudBerry support involvement is required In order to help you quickly deliver logs and further debug information all products contain diagnostic section which is designed for Collect a product logs Send to support All Diagnostic information is available under Tools rarr Diagnostic CloudBerry Lab Support toolsimageskb1026CloudBerryLabtoolsdiagnosticpng In some cases Solutions Architect team andor Support team may require more detailed journaling All CloudBerry tools can be set to High level of logging Product logs can be set to No log Low level default or High level troubleshooting We recommend to have logs set to Low level when operating normally otherwise log files grow fast what may end up with insufficient space in your C or other depends on Log to folder path or root path if you are Linux or Mac CloudBerry Lab set level of loggingimageskb1026CloudBerrylogslevelpng In certain cases you may want to check logs yourself You can find all logs by default CProgramDataCloudBerry LabLogs You can change this path in Tools rarr Options rarr Logging rarr Log to folder"},{"title":"Managed Backup Service (MBS) TCP Ports configuration","tags":["mbs"],"kbid":1027,"author":"Eugene","href":"/kb1027","content":"The Managed Backup Service architecture listed below required certain reconfiguration configuration in clients OS or even in general Proxy Firewall system if the client is behind NAT Managed Backup Service MBS from CloudBerry Labimageskb1027mbshowitworkspng Consider following things to be available when setting up CloudBerry lab clients software TCP ports 443 used for authentication 80 online backup access 119 8119 8120 remote management IP addresses 5267137 52540159 522040101"},{"title":"How to obtain logs CloudBerry Backup for macOS?","tags":["mac","cli"],"kbid":1028,"author":"Eugene","href":"/kb1028","content":"CloudBerry Backup for Mac OS X helps customers to backup folders and files to object storage like AWS S3 Microsoft Azure etc It is quite stable and mature product however sometimes you may meet small glitches or operation issues The best way to get such situations resolved is to submit support case In order to receive quick competent and consistent reply it is good practice to supply such request with all available information logs configuration files GUI information The best and easiest way to liaise with technical consultants from CloudBerry Lab Architects or Support is to submit and send with short description logs from GUI In the interface of the product locate Settings rarr Diagnostic as per below picture CloudBerry Backup for Mac OS X logs from GUIimageskb1028cloudberrylabmacguisubmitlogsjpg We suggest the following approach to simplify and better escalation User Name should be valid and we should be able to find it in our system use your registration name Message should contain short problem description and if applicable for instant you had call chat with CloudBerry representatives prior submitting name of that contact from CloudBerry lab The above tips drive such ticket to the appropriate person with minimum iterations Command line information Depends on your product Standalone or MBS CloudBerry Backup for macOS keeps clear structure of troubleshooting information in the following path optlocalCloudBerry Backup for Standalone or optlocalproductname MBS where productname name of your product in MBS Advanced Branding section The below is the example of home folder for the productname Backup from MBS Just take required files in most cases CloudBerry team will ask you about your logs tree 200000 config accounts 2443d4ff88ae45e4af38f0d46589f3fc cbbackupdb cbbackupdbshm cbbackupdbwal cloudBackupconf scheduleloc settingsconf logs Outerr Outlog OutRMerr OutRMlog logGUIlog logLocalDaemonlog logRemoteDaemonlog logworker52d86932792a4dc78187805406d70a98log plans 52d86932792a4dc78187805406d70a98cbb The path contains the following information config information about account online account if persistent product settings plans directory with structured plans configuration each plan is XML structured file with settings for backup restore plan logs most important directory for troubleshooting and debugging when requesting support assistance There are some other folders and files but they are not required for the troubleshooting"},{"title":"Error: License not verified! product can't backup now","tags":["linux","cli"],"kbid":1029,"author":"Eugene","href":"/kb1029","content":" Problem CloudBerry Backup for Linux1f46d3be comes with command line interface4ac3b676 CLI what allows customer to configure file level backup for Linux content ie files directories CLI is very powerful tool operate entire backup ecosystem ie configure account configure license create plans manage plans actually all what is possible through regular GUI of CloudBerry Lab for Linux with Graphic interface Managed backupf239e3e0 edition the one which you obtain from MBS needs to be linked to certain user first and then activated So if you missed the fist step and trying to activate your license you are going to see the following error message cbb activateLicense e youremaildomaincom t online Backup Command Line Interface started error License not verified product cant backup now Resolution In order to resolve the issue you need to go through the following steps Link your copy of downloaded product from MBS to existing user Activate either commercial or trial license cbb addAccount e youremaildomaincom p Password ssl yesno This will link your software to appropriate account in MBS Next step is to activate license If you have commercial license recently purchased or want to reused released license cbb activateLicense e youremaildomaincom k Alternatively you can request 15 days trial using the following syntax cbb activateLicense e youremaildomaincom t For the Standalone product check CLIhttpswwwcloudberrylabcombackupcmdlinuxaspx user guide 1f46d3be httpwwwcloudberrylabcombackuplinuxaspx CloudBerry Lab for Linux OS 4ac3b676 httpwwwcloudberrylabcombackupcmdnixaspx Command Line Interface for Linux f239e3e0 httpwwwcloudberrylabcommanagedonlinebackupserviceamazons3azureaspx Managed backup"},{"title":"Nodeps installation of CBL for Linux","tags":["linux","cli"],"kbid":1030,"author":"Eugene","href":"/kb1030","content":"CloudBerry Backup for Linux designed to help customers to protect their file system from disaster and keep certain retention policy of files and folders offsite public cloud ie S3 It is possible to install CloudBerry Lab for Linux even with no UI but you may face the GL dependencies request which you need to either skip or satisfy sudo rpm i rhrpm error Failed dependencies libpcre16so064bit is needed by cloudberryonlinebackupx8664 How to skip GL dependencies for Linux CLI installation CloudBerry Lab There is no problem to install them but you probably dont need them if they are related to GL graphic interface of your Linux Unix So to save time and install the CBL product do the following sudo rpm i rh6rpm nodeps nodeps flag just ignores all dependencies so it is important if you make sure you have them related to graphic interface only rh6rpm is one of the build for RedHat from CloudBerry Lab for Linux pagehttpwwwcloudberrylabcomdownloadthanksaspxprodcbbub1214"},{"title":"Cannot locate the specified file(s) or folder(s): \\\\unc-path or local path","tags":["backup","unc"],"kbid":1031,"author":"Eugene","href":"/kb1031","content":" Problem You have your CloudBerry Lab for Server or any other edition installed and configured first backup plan You did include all your system volume and few network shares When you execute your plan but it fails with the following message Cannot locate the specified files or folders uncpath or local path Resolution By default your CloudBerry service is run on behalf of Local system account that sometimes does not have enough permissions to access certain files and folders in your structure ie networks shares others owners folders and files To change the service account you can do either in services servicesmsc or in the CloudBerry GUI Go to Tools rarr Change Service Account Change Service Account for CloudBerry Lab Backup for Windowsimageskb1031changeserviceaccountcblbackuppng Set your user accordingly make sure it has required rights to your data source Set Service Account for CloudBerry Lab for Backup fow Windowsimageskb1031setserviceaccountforcblbackuppng"},{"title":"Current license or ESXi version prohibits execution of the requested operation","tags":["vmware","vm"],"kbid":1032,"author":"Eugene","href":"/kb1032","content":" Problem Youve configured VMware Hypervisor free edition of VMware ESXi and deployed few virtual machines Your free host does not support clustering so it is not possible to use vMotion and things like that but your major idea is to consolidate your Virtual Machines having the basic benefit of virtualization in place Afterwards you have CloudBerry lab installed and trying to configure your CloudBerry Backup for VMware and HyperV64712d4c but you get the following error Current license or ESXi version prohibits execution of the requested operation The problem is that free VMware does not provide full support of VMware vSphere Storage APIs Data Protection formerly known as VMware vStorage APIs for Data Protection or VADP 64712d4c httpwwwcloudberrylabcomvm CloudBerry Backup for VMware and HyperV Resolution There are several ways of resolving this situation All VMware centric backup tools 3d party will tell you to upgrade your VMware to at least Essentials SMB solution as any commercial license supports VADP in its full size If it is not possible for certain reason no budget etc there is agent for certain OS platform that you can deploy and use ie CloudBerry Backup for Windows98182174 or Linux backupd14353a4 or Mac OS X8f92c9f6 This is not something you would like to have with your Virtual ecosystem but at least it guarantees protection of your data at a lower cost 98182174 httpwwwcloudberrylabcomcloudbackupwindowsdesktopaspx CloudBerry Backup for Windows d14353a4 httpwwwcloudberrylabcombackuplinuxaspx Linux backup 8f92c9f6 httpwwwcloudberrylabcombackupmacaspx Backup for Mac OS X VMware in trial mode 30 60 days trial is not free it is commercial license and have full VADP support The easiest way to support VADP is to upgrade your VMware farm to commercial license at least essentials Check httpswwwvmwarecomproductsvspherecomparehttpswwwvmwarecomproductsvspherecompare for more details"},{"title":"The underlying connection was closed: An unexpected error occurred on a send","tags":["MS Windows 2003","OpenSSL"],"kbid":1033,"author":"Eugene","href":"/kb1033","content":" Problem Youve signed up into Managed backup servicehttpcloudberrylabcommbs from Cloudberry lab configured your companies and tenants users requested custom build of Cloudberry backup product for your Microsoft Windows 2003 Bare metal or Desktop Once software downloaded and installed your are trying to activate it but getting the following error message Windows 2003 error message with old SSLimageswindows2003errorwitholdsslpng This problem is related to old OpenSSL protocol and should be updated Resolution In order to resolve the problem you need to obtain the following Microsoft hot fixes httpssupportmicrosoftcomenuskb948963httpssupportmicrosoftcomenuskb948963 httpssupportmicrosoftcomenuskb968730httpssupportmicrosoftcomenuskb968730 Make sure reboot the server once updates done"},{"title":"VMware plan configuration returns wrong FQDN when configuring plan","tags":["VMware","vm"],"kbid":1035,"author":"Eugene","href":"/kb1035","content":" This article will be deleted as this product behaviour has been fixed However we keep this for the customer with old version of the CB Backup 50 or earlier Problem CloudBerry Backup VM edition is agentless solution and designed to work with VMware Virtual Machines Our VM edition is not that mature so the main position of this product is decent VM archiving When you configure backup plan and it returns wrong FQDN even you enter IP This actually returned by VMware API for Data Protection VADP and CloudBerry does not handle this accordingly When your VMware nodes are not part of the domain they may have wrong host files configured Resolution This can be resolved by the following workaround we are set to address this issue in one of the next release but for now 1 Go to your CWindowsSystem32Driversetchosts 2 Add new line with IPaddress of your VMware farm FQDN for instance 19216811 vmwaredomain 3 Might be ipconfig flushdns required Example type CWindowsSystem32Driversetchosts something else 127001 fijicloudlocal Check if you can nslookup your IP and it touches your FQDN ping it to see if it returns ICMP Configure your plan"},{"title":"Microsoft Visual C++ 2008 SP1 Redistributable Package (x64) required","tags":["MS Windows 2008"],"kbid":1036,"author":"Eugene","href":"/kb1036","content":" Problem See this error message during CloudBerry Backup installation Microsoft Visual C 2008 SP1 Redistributable Package x64 Resolution Download and install the following package Microsoft Visual C 2008 SP1 Redistributable Package x64httpwwwmicrosoftcomenusdownloaddetailsaspxid2092"},{"title":"«Invalid username or password» when sign in to Cloudberry Backup client received from service provider?","tags":["MBS"],"kbid":1038,"author":"Eugene","href":"/kb1038","content":" Problem When trying to sign in to Cloudberry Backup client downloaded from MBS getting the following error Cloudberry Backup invalid username or passwordimagesmbsinvalidusernamejpg This is because the username and password are taken from Admin section rather Users However there might be username or password mistype double check your data Resolution All users for Cloudberry Backup clients should be either created or approved when using AD bridge through Users section pictured below Cloudberry Managed Backup Service Usersimagescloudberrylabmbsusersjpg"},{"title":"How to speed up backup plans for Backblaze B2 (Memory Manager Usage)","kbid":1046,"author":"Eugene","href":"/kb1046","content":" Problem Since end of H1 2016 Cloudberry lab supports Backblaze B2 Cloud Storage7d0281d4 object storage When operating with large files eg Image Based backup or large archives customers may experience slow backup speed This occurs because Backblaze B2 uses fixed chunk size 100 MB and Cloudberry prepares chunks in memory for instance with default settings of 6 thread count and 100 MB chunk size the following happens 6 threadcount x 100 MB x 2 workflows 1200 MB is required By default the amount of allocated memory is 300 MB and is not available in the UI however it is possible to change in settingslist 7d0281d4 httpswwwbackblazecomb2cloudstoragehtml Backblack B2 Cloud storage Resolution 1 Close Cloudberrys client on the computer you are backing up 2 In your favorite text editor open programdataenginesettingslist change Product Name to the product build name eg CloudBerry Backup Enterprise Edition for Cloudberry Backup Ultimate Edition Search for MemoryManagerMaxMemoryUsage in this file The value of this setting will be 314572800 bytes of 3145728 MB We recommend this figure should be thread count x 100MB For example if you have set your thread count to 20 set this number to 2000000000 Thats 20 threads x 100 MB 2000 MB or 2000000000 bytes Ensure that you have this much free RAM in your system to ensure best performance If you dont see MemoryManagerMaxMemoryUsage in your enginesettingslist just put it between major tag anywhere and set the number accordingly 3 Start the Cloudberry client and run the backup"},{"title":"Universal Object Storage seeding","kbid":1047,"author":"Eugene","href":"/kb1047","content":" Problem Initial full backup is always painful and may take significant amount of time when offloading data to object storage over Internet uplink Amazon Web Services AWS has Snowballc290c7d3 service basically it is removable storage they ship to customer for initial seeding and it should be returned back once data is on it and they seed it for further incremental runs Other providers have their options to seed data Cloudberry Backup supports outofthebox AWS Snowball but not for other S3 compatible providers Data seeding is not that complicated but from the other hand Cloudberry requires certain folders files structure of is backups what is not possible to accomplish over simple data offload into directly attached storage that can be shipped further to storage provider eg Windows Windows file systems does not support colon symbol in files folder names and this is required by Cloudberry backup structure c290c7d3 httpsawsamazoncomimportexport AWS ImportExport Snowball Resolution Seeding to object storage can be done over S3 Compatible appliance Virtual Machine that customers can download and use as middleware between data and colon supported storage eg NAS with linux file system Prerequisites Download Cloudberry S3 compatible appliance29ba6979 It is tiny linux machine Debian 8 jessie It is with based system no UI It is with SSH server It is with Minio S3 compatible as our seeding middleware It is with v2v4 S3 API signature support Get NAS or other storage with file system that supports colon consult with your storage provider NAS supplier Prepare your backup strategy eg backup plan groups consider encryption compression policies 29ba6979 httpss3euwest1amazonawscomcloudberrylabkbdownloadseedingappliancetargz S3 compatible appliance Configuration of Appliance S3 compatible appliance is available in VMware Virtual Machine OVF 202e8cf8f4 formfactor Deploy new virtual machine can be on one of your VMware ESXi or VMware Workstation Request another formfactor from sateamcloudberrylabcom354792cd or if you experience issues with downloading this archive once this one does not work or you dont have certain facilities to run it 2e8cf8f4 httpsenwikipediaorgwikiOpenVirtualizationFormat Open Virtualization Format OVF 20 354792cd mailtosateamcloudberrylabcom Solutions Architect team Cloudberry Backup initial seedingimagescloudberryseedings3miniopng Start the Virtual Appliance and login with cloudberryPaw0rd Elevate your permissions to root if you experience issues with mounting shares Yes this is not best practice with rootPaw0rd Mount your remote share NAS with the following example highlight bash mount t nfs folder mntnas ls mntnas check your mount create delete files folders just to make sure you have permissions endhighlight Go to your home cloudberry user directory homecloudberry and execute the following highlight bash minio server mntnas Endpoint http9000 http9000 AccessKey SecretKey Region useast1 Browser Access http9000 http9000 Commandline Access httpsdocsminioiodocsminioclientquickstartguide mc config host add myminio http9000 Object API Amazon S3 compatible Go httpsdocsminioiodocsgolangclientquickstartguide Java httpsdocsminioiodocsjavaclientquickstartguide Python httpsdocsminioiodocspythonclientquickstartguide JavaScript httpsdocsminioiodocsjavascriptclientquickstartguide endhighlight This means that you have your S3 compatible server within Appliance running with v4 Signature support Now we need proxy do the following highlight bash cd GOPATHbin s3v2tov4proxy l 8000 f httplocalhost9000 access secret endhighlight If you dont see any errors you are set now with S3 compatible middleware and ready to do rest of configuration in Cloudberry lab products Configuration of Cloudberry Backup Download and install if you have not done yet Cloudberry Backup for Windows or Mac Linux And start configuartion of your storage account Cloudberry Backup configuration seedingimagescloudberrystorageconfigurationseedingjpg Next step is to configure your backup plan Image Based File folder etc use your recently created storage account for this Run backup plan and make sure you have data written to your NAS storage and the structure is not changed you should be able to see colon element in folders files For example in path with files where disk letter eg C For example highlight bash cloudberrycloudberrymntqnapbackupsbackupCBBDC tree C acl 20160902151528 8bae0af739186d8461df58591a9720f1 Distribs bootableiso 20160726133432 bootableiso endhighlight Seeding is ready and can be shipped to storage provider Reuse seeding and keep incremental runs Your storage provider should offload data to datacenter and provider credentials and endpoint to connect Configure new object storage endpoint accordingly in the similar way we did for the seeding storage Reconfigure your backup plan by changing storage account You may need to Syncronize Repository in Tools rarr Options rarr Repository in order to list existing backup data and fit it with Cloudberry SQLite backend Nota bene Please consult with sateamcloudberrylabcom354792cd team prior you go seeding"},{"title":"How to upgrade CloudBerry Backup license","kbid":1048,"author":"Anton","href":"/kb1048","content":" Upgrading Cloudberry Backup license for Windows client Most part of CloudBerry Backup standalone editions working under Windows OS are limited to 1 TB of cloud storage they can handle There are also 2 editions that are not limited Virtual machine and Ultimate which used to be Enterprise previously editions For Desktop Free edition this limitation is only 200 GB All the editions are not limited if backing up to localnetwork filesystems Release procedure In order to perform to upgrade your license you need to click on main button go to Help gt Release license CloudBerry Backup for Mac OS X logs from GUIimages1048releaseliccbbwinpng Upgrade procedure First of all open the link below and provide your license key and email httpwwwcloudberrylabcomupgradelicensereleaseaspx Then click check and then pick what is the desired license type you want for the product CloudBerry Backup for Mac OS X CLI with logs configuration outputimages1048releaselicwebpng Click Check out and you will be redirected to our payment processor where you can provide your payment method and proceed with payment CloudBerry Backup for Mac OS X CLI with logs configuration outputimages1048licupgradecheckoutpng Please note that this will not work for Managed Backup Service"},{"title":"MS Exchange Server 2007: Connection to the remote server failed","kbid":1050,"author":"Eugene","href":"/kb1050","content":" Problem You have your Cloudberry Backup for MS Exchange installed on your machine You are creating the backup plan and receive an error Connecting to the remote server failed with the following error message The WinRM client sent a request to an HTTP server and got a response saying the requested HTTP URL was not available on the step where you should specify the Databases for upload Like on the screenshot below The connection to remote server failedimagesmsexchangeerrorpng Resolution 1 Close Cloudberrys client on the computer you are backing up 2 Edit enginesettingslist its located in CProgramDataCloudBerryLabCloudBerry Backup and change ltIsExchange2007gtfalseltIsExchange2007gttoltIsExchange2007gttrueltIsExchange2007gt 3 Start the Cloudberry client and run the backup"},{"title":"Seeding data via CloudBerry Backup part II","kbid":1051,"author":"Robert","href":"/kb1051","content":" Problem While CloudBerry Backup is great for daytoday use the initial backup may pose a problem for users with slow or pricey internet connection Suppose you installed Cloudberry Backup on your computer and want to start backing up one of your hard drives If the volume of the data is relatively small the task is pretty much straightforward set up a backup plan and run it However if youre working with rather large volumes of data poor or expensive internet connection may urge you to find a different solution to this problem Namely use a different computer that has a decent connection Naturally CloudBerry Backup stores files in a certain way certain file structure certain file naming conventions etc So you cannot just dump your files into your cloud storage on one computer and then expect CloudBerry Backup on another computer to just pick up those files during the next backup plan execution Resolution There is a workaround for this issue however You have two options Use Custom Mode when creating a backup plan This is the easier option That way you dont need to get technical and tinker with buckets repository syncs changing prefixes setting identical file structures on both computers etc Note that this option is fairly unsophisticated and does not allow you to use encryption In summary little effort and few options Use Advanced Mode when creating a backup plan This option gives you greater flexibility when it comes to backup options while requiring extra effort in setting things up properly on both machines In summary extra effort and extra options This article is only covering the second option To learn more about the first option read this article Without further ado lets get to the tutorial Lets talk about the Advanced Mode in detail The main idea here is to ensure that both computers have identical settings Namely backup prefix file structure and cloud storage credentials First ensure that file structure is the same on both machines For instance if the folder Docs is located at CDocs on the slow PC ensure that it is also located at CDocs on the fast PC so that both computers will upload into the same cloud folder Second ensure that you have the same cloud credentials security keys and the bucket in the Account Settings Third ensure that you have the same backup prefix on both machines by going to Edit Accounts Select your account and click Edit Then click Advanced settings Enter any prefix you want just keep in mind that you have to enter the same prefix on both machines to have smooth and successful backups Now you need to copy your large files onto an external hard drive In our example a folder named Docs was copied from the slow PC onto a USB flash drive This folder contains all the large files that would take forever to upload on the slow PC Now open CloudBerry Backup on the fast PC and enter your Amazon credentials security keys Then create a backup plan as follows Launch the Backup Wizard and click Next Select your storage and click Next Pick a name for your backup plan and click Next Select Advanced Mode Click Next Specify the folder you wish to upload Click Next Enable compression or encryption if needed Click Next Continue setting up the plan Upon finishing select the Run now checkbox and then wait intil the backup plan execution completes Your data should now be successfully uploaded into the specified folder in the cloud storage Notice that we only have 7 files in the Dos folder Now lets get back to that very folder on the Slow PC add a file to it and do the same process again As you see on the screenshot below 2 files were added their names start with NEW Launch CloudBerry Backup on the slow PC and create the exact same backup plan as you did on the fast PC If you have enabled encryption make sure that you use the same encryption type and the same passcode Before you run the plan ensure that all repositories are synced to avoid reuploading large files To do so go to Cloudberry Options Under Repository click Synchronize Repository and then click Synchronize Now Then close the popup window and run the backup plan All added files should appear in your cloud storage Likewise whenever you modify any files within that folder just run the backup plan and youre good to go If you still have any questions regarding seeding data feel free to drop us a line at supportcloudberrylabcom and we will get back to you shortly"},{"title":"Seeding data via CloudBerry Backup part I","kbid":1052,"href":"/kb1052","content":" Problem While CloudBerry Backup is great for daytoday use the initial backup may pose a problem for users with slow or pricey internet connection Suppose you installed Cloudberry Backup on your computer and want to start backing up one of your hard drives If the volume of data is relatively small the task is pretty much straightforward set up a backup plan and run it However if youre working with rather large volumes of data poor or expensive internet connection may urge you to find a different solution to this problem Namely use a different computer that has a decent connection Naturally CloudBerry Backup stores files in a certain way certain file structure certain file naming conventions etc So you cannot just dump your files into your cloud storage on one computer and then expect CloudBerry Backup on another computer to just pick up those files during the next backup plan execution Resolution There is a workaround for this issue however You have two options 1 Use Custom Mode when creating a backup plan This is the easier option That way you dont need to get technical and tinker with buckets repository syncs changing prefixes setting identical file structures on both computers etc Note that this option is fairly unsophisticated and does not allow you to use encryption In summary little effort and few options 2 Use Advanced Mode when creating a backup plan This option gives you greater flexibility when it comes to backup options while requiring extra effort in setting things up properly on both machines In summary extra effort and extra options This article is only covering the first option To learn more about the second option read thishttpkbcloudberrylabcomkb1051 article Without further ado lets get to the tutorial First things first you need to copy your large files onto an external hard drive In our example a folder named Docs was copied from the slow PC onto a USB flash drive This folder contains all the large files that would take forever to upload on the slow PC Now open CloudBerry Backup on the fast PC and enter your Amazon credentials security keys Then create a backup plan as follows 1 Launch the Backup Wizard and click Next 2 Select your storage and click Next 3 Pick a name for your backup plan and click Next 4 Select Custom Mode and then select the folder in your cloud storage where you wish to store your files Click Next two times 5 Now you can select the folder you want to back up Docs in our case Click Next 6 Now continue setting up the plan Upon finishing run the plan once and your data should be successfully uploaded into the specified folder in the cloud storage Notice that we only have 7 files in the Docs folder Now lets get back to that very folder on the Slow PC add a file to it and do the same process again As you see on the screenshot below 2 files were added their names start with NEW Launch CloudBerry Backup on the slow PC and create the exact same backup plan as you did on the fast PC Before you run the plan ensure that all repositories are synced to avoid reuploading large files To do so go to Cloudberry Options Under Repository click Synchronize Repository and then click Synchronize Now Then close the popup window and run the backup plan All added files should appear in your cloud storage Likewise whenever you modify any files within that folder just run the backup plan and youre good to go If you still have any questions regarding seeding data feel free to drop us a line at supportcloudberrylabcommailtosupportcloudberrylabcom and we will get back to you shortly"},{"title":"How to configure SPF (Sender Policy Framework) record for MBS","kbid":1053,"author":"Eugene","href":"/kb1053","content":" Problem An SPF record is a type of Domain Name Service DNS record that identifies which mail servers are permitted to send email on behalf of your domain The purpose of an SPF record is to prevent spammers from sending messages with forged From addresses at your domain Recipients can refer to the SPF record to determine whether a message purporting to be from your domain comes from an authorized mail server For example suppose that your domain examplecom uses onprem mail server You create an SPF record that identifies the CloudBerry Lab mail servers as the authorized mail servers for your domain When a recipients mail server receives a message from userexamplecom it can check the SPF record for examplecom to determine whether it is a valid message If the message comes from a server other than onprem mail servers listed in the SPF record the recipients mail server can reject it as spam Thats why it is very important to have SPF record in your domain records Resolution Set the following SPF record to your domain TXT vspf1 ip450192436 all where TXT domain record type second line value of this record ip4 IP address of CloudBerry Lab SMTP server In case of other records you can use include syntax in the following format TXT vspf1 includespfgooglecom ip450192436 all "},{"title":"How to restore image based backup to EC2 with partitions large 1TB","kbid":1054,"author":"Eugene","href":"/kb1054","content":" Problem Imagebased previously called Bare Metal backup plans were designed to help customers protect their Windows computers It integrates with Microsoft VSS technology Windows Shadow copy and guarantees transactionally consistent backup It allows administrators to exclude unwanted files in certain partitions and the partitions themselves from being restored Backup can be restored as an EC2 instance AWS Virtual Machine but having partitions of over 1Tb can prevent this action and cause the following error message in the CloudBerry Backup console or log files selected partitions exceed 1TB in size This is an artificial limitation due to the nature of the restoration procedure Resolution There are several scenarios all of which are based on the CloudBerry restoration options Scenario 1 You have Image Based backup with boot disk over 1 Tb CloudBerry Restore plans can be configured certain with partitions resized and certain files and folders excluded Both options allow to shrink the target EBS volume to the size that AWS can accept through a method we use for restoration Follow the instructions below to decrease the amount of data included in the restored disk In the restore wizard on the Select Partitions step make the following changes CloudBerry Restore to EC2 select partitionsimageskb1054selectpartitionsjpg This step contains hidden options to 1 resize the target partition 2 exclude files and folders Resize your partition to the maximum of 1Tb content exclusion can be helpful to exclude the unnecessary data from the system boot Partition resize CloudBerry Backupimageskb1054resizepartitionjpg Afterward just follow the wizard and launch the restoration process This will launch an EC2 instance with your OS inside Scenario 2 You have an imagebased backup data disk with no OS that is over 1Tb This scenario requires the EC2 instance with Windows OS to be launched in the AWS Cloud This scenario also requires the CloudBerry Backup product to be installed on this Guest OS Once done sync your repository according to this articlehttpwwwcloudberrylabcombloghowtocontinuebackuponanothercomputer in our blog Those steps allow you to have your backup data listed in the newly installed CloudBerry Backup This should be an imagebased backup so make sure you configure your storage account and select the backup prefix accordingly AWS EBS volume supports volumes ranging from 1 to 16384 GiB Amazon Web Services EBS volume configurationimageskb1054awsebsvolumeconfigurationjpg Create a volume that can fit your data and attach it to your EC2 instance Next step is to restore the disk from the imagebased backup as Physical disk Hit Restore select the storage account with the imagebased backup select other options as you see fit eg restoration point plan name etc Make sure you select Restore as physical disk at the Type of data step to restore CloudBerry Backup Restore as physical diskimageskb1054restoreasphysicaldiskjpg Select partitions to restore and set the destination CloudBerry Backup restore 16 Tb destinationimageskb1054restoredestinationjpg Complete the wizard and run the plan"},{"title":"How to fix 'Received an unexpected EOF or 0 bytes from the transport stream' on Windows Server 2003?","kbid":1055,"author":"Eugene","href":"/kb1055","content":" Problem Backup plans sometimes fail to run smoothly You may occasionally encounter the Received an unexpected EOF or 0 bytes from the transport stream error It is a wellknown issue that plagues Windows Server 2003 All you need to resolve this issue is to install certain updates Resolution Please download and install the following updates httpssupportmicrosoftcomenuskb948963httpssupportmicrosoftcomenuskb948963 httpssupportmicrosoftcomenuskb968730httpssupportmicrosoftcomenuskb968730 On each of the 2 aforementioned pages you should click the Hotfix download available blue button and then select the appropriate Windows version bitness and language you might need to open the Show hot fixes for all platforms and languages link Then reboot the server and verify that the issue is resolved The aforementioned pages also contain the explanation for the cause of the error"},{"title":"How to restore your desktop OS as an EC2 instance","tags":["ec2","desktop"],"kbid":1060,"author":"Alex","href":"/kb1060","content":" Problem Amazon EC2 presents a true virtual computing environment allowing you to use web service interfaces to launch instances with a variety of operating systems load them with your custom application environment and run your image using as many or as few systems as you desire With Cloudberry Backup it is possible to protect yourself from the scenario when your system fails We call it Disaster Recovery Just have at least one copy of your system in the backup destination and proceed with restore as an EC2 instance Many of our customers ask us Is it possible to restore my Windows 7 or my Windows 8 or other OS as an EC2 instance And the answer is Yes Follow the steps below and spin up your desktop OS in the cloud Resolution Before you begin you should be aware of some limitations and steps without which it would be impossible to import your desktop OS to AWS environment Dont forget about the role of VMimporthttpwwwcloudberrylabcombloghowtoconfigurevmimportrole in your AWS account VM ImportExport supports importing Windows instances with the following file systems MBRpartitioned volumes that are formatted using the NTFS file system and GUIDPartitionTablepartitioned volumes are not supported Your Windows instance should be BIOSbooted Currently Amazon EC2 service doesnt have an option to enable UEFI booting of instances And last but not least you should know that during the restoration process you must select the Create an AMI Amazon Machine Image option It will create an AMI in your AWS account before launching an EC2 instance Restore your Windows7Windows8Windows10 as EC2 Click Restore select Restore as Amazon EC2 Instance and dont forget to enable Create AMI Amazon Machine Image option Hit Restore button and choose Restore as Amazon EC2 Instanceimageskb1060Screenshot2png Or you can go the easy way Easier way to restore as EC2imageskb1060Screenshot3png Specify your target EC2 instance details Target EC2 instance detailsimageskb1060Screenshot4png Once your EC2 Instance is restored you can check created AMI and your restored virtual machine in your AWS account EC2 dashboardimageskb1060Screenshot5png Resume Now you can restore not only Server versions of OS as EC2 with Cloudberry but you can restore Windows7 Windows8 Windows10 as well Cloudberry always tries to fit the latest updates in the cloud world According to the AWS documentationhttpdocsawsamazoncomvmimportlatestuserguidevmimportimageimporthtmlshortFootertrueprerequisitesimage you can use a bunch of operating systems that can be imported to EC2 In this topic we are talking about Desktop OS versions Here at Cloudberry we have tested the restore with Windows7x64 Windows8x64 and Windows10x64 Just dont forget that 1 Your system must be BIOS booted 2 Your volumes must be MBRpartitioned 3 You need choose Create an AMI Amazon Machine Image option Otherwise you will get ClientError Unsupported Windows OS Download CloudBerry Backuphttpswwwcloudberrylabcom and give it a try"},{"title":"Can not specify all Azure Virtual Machine instance details in the restore wizard","kbid":1063,"href":"/kb1063","content":" Problem Lets say you have one copy of your image in the cloud and you need to perform a restore to Azure VM You select the data for restore and your account but you cannot select some of your resources you can not list your network subnet storage andor your containers imageskb1063screenshotpng What could be the reason Reasons and Resolutions First reason specified location Make sure that youve selected the right region where you have all your resources created And make sure that the Virtual Network Storage and Container are created in the same region Second reason you are using Classic Deployment Classic Azure Portalhttpsmanagewindowsazurecom but not Resource Manager New Azure Portalhttpsazuremicrosoftcomenusfeaturesazureportal Cloudberry Backup supports only Resource Manager for restoring virtual machines If you are using Classic Deployment and you have the Virtual Network Subnets Storage and Containers created in the old portal you wont be able to list them in the Cloudberry restore wizard Its not a problem since you can log in to the Resource Manager Then add Storage Containers and Virtual Network under your resource group Dont forget that all these resources should be in one location region Once you added all the necessary resources return back to the restore wizard complete filling out the instance details and finish your restoration imageskb1063screenshot3png"},{"title":"Counting requests for every backup plan","kbid":1066,"author":"Anton","href":"/kb1066","content":" Problem Your cloud storage provider sent you monthly bill and detailed explanation what you were charged for And surprisingly you realize that storage contains only 6070 of the entire bill The rest of that amount you need to pay for requests Resolution In order to have a better visibility on what you consume from storage providers subscription weve made this setting in our backup agent Go to the following folder and locate enginesettingslist file For standalone backup CProgramDataCloudBerryLabCloudBerry Backupenginesettingslist For Managed backup this will be something different depending on the name of the product that you made but still it will be in ProgramData folder Example for the Company ABC CProgramDataCompany ABCenginesettingslist In enginesettingslist you need to put the following text somewhere in the end ltLogRequestCountersOnExitgttrueltLogRequestCountersOnExitgt This setting should work for all backup versions but starting from Backup 54 you should switch to the following setting ltLogRequestsOnExitgttrueltLogRequestsOnExitgt Run your plan Click on Tools rarr Diagnostic rarr Open in folder Find the latest modified file with log extension file name is your backup plan ID In the end of the file you will see 20161215 140235207 SERV 1 NOTICE Uploaded 2769 KB Deleted 0 Failed 0 20161215 140235249 SERV 1 NOTICE Request GET success 15 failed 0 20161215 140235249 SERV 1 NOTICE Request PUT success 15 failed 0 20161215 140235249 SERV 1 NOTICE Request HEAD success 4 failed 0 20161215 140235249 SERV 1 NOTICE Request DELETE success 15 failed 0 imageskb1066backuplogpng Now you can see how many requests have been sent"},{"title":"Local repository synchronization after Custom mode backup","kbid":1070,"href":"/kb1070","content":" Problem 1 You created your backup by using Custom backup mode 2 You need to restore the data on another computer You added an account You set up the backup prefix in the advanced settings Your local repository was synchronized You dont see the needed data under your account Resolution Once you proceed with all steps mentioned above make the following 1 Run command prompt under certain rights 2 Navigate to the Cloudberry Backup installation folder 3 Execute the following command cbbexe account s youraccountname custom foldername youraccountname is your cloud storage account name foldername is a name of the folder that you can not see under your bucketcontainer"},{"title":"Cannot upload files, storage cap exceeded for B2 BackBlaze","kbid":1071,"href":"/kb1071","content":" Problem During the backup of your data you receive an error Cannot upload files storage cap exceeded See the Caps Alerts page to increase your cap You may also receive the notification from B2 BackBlaze imagesstoragecapexceededb2png Suggestions and Resolutions You have reached the limit of the free Backblaze Daily Storage Cap To increase your Daily Storage Cap or to change your Cap Notification Settings log on to the Caps Alerts page under your BackBlaze account and edit Caps limits imagescapsalertspng"},{"title":"Local repository migration to a different location","kbid":1072,"author":"Alex","href":"/kb1072","content":" Problem Cloudberry Backup stores the information about uploaded data to the backup destination in local repository sqlite database This small database may grow from day to day It depends on the amount of data that you might have been uploading according to your retention policies or data importance By default this database is located in the program data directory Where you can find products configuration files log files and other By default its located on disk C But what should you do in case you dont have enough disk space but your local repository consumes several Gigabytes of data Suggestions and Resolutions 1 You can shrink database by going to the Tools Options Repository Shrink Database button It will remove all empty lines all information about outdated accounts history or cache In some cases you will win several Megabytes But what if its not enough 2 You can move your repository somewhere outside the disk C To the disk with more free space For this you need go to Tools Options Repository Change the location folder imagesrepolocationpng NB The database will be moved not copied to a new location Make sure that your UI is running under administrator Make sure that your Backup service is stopped Otherwise you will receive an error imagesmovingrepositorypng Once you run the Cloudberry Backup with certain rights and stopped the backup service you should receive the following notification that the database location successfully changed imagesdatabaselocationchangedpng Restart your backup agent the service and check that you can see all your data under the Backup Storage tab in UI"},{"title":"The specified path, file name, or both are too long","kbid":1073,"author":"Alex","href":"/kb1073","content":" Problem During the data upload you may see an error The specified path file name or both are too long or The maximum file name limit or path length is exceeded Suggestions and Resolutions Here you can find the limits for the entire path and file names For all operating systems that are supported by Cloudberry tg bordercollapsecollapseborderspacing0margin0px auto tg tdfontfamilyArial sansseriffontsize14pxpadding10px 5pxborderstylesolidborderwidth1pxoverflowhiddenwordbreaknormal tg thfontfamilyArial sansseriffontsize14pxfontweightnormalpadding10px 5pxborderstylesolidborderwidth1pxoverflowhiddenwordbreaknormal tg tgyw4lverticalaligntop Limit for Windows MacLinux entire path 4096 bytes unlimited file name 255 bytes 255 bytes For some cloud storage providers the entire path andor file names length might be limited individually"},{"title":"Sorry, but we're having trouble signing you in. We received a bad request","kbid":1075,"author":"Alex","href":"/kb1075","content":" Problem When you add an Azure VM account under your MBS control panel you need add your Azure Portal credentials by hitting on Sign in button Then you should be able to choose your Tenant ID and Subscription But by some reasons you gen an error from Azure Sorry but were having trouble signing you in We received a bad request Suggestions and Resolutions Commonly its connected with the fact that you trying to authorize under user who is not able to get access to your subscriptionsservices According to our recommendations for proceed with Azure VM restore you need to have working or school account type Working or school account have 2 types of users Domain or created users Invited users Invited users do not have the rights to proceed with Azure VM restore By following the steps below in the end you will be able to set up an Azure VM account and continue with restore First of all you need to create a user Under your Azure Portal navigate to Azure Active Directory then Domain Names and copy on of the existing domain name imagesdomainnamespng Once you copieddecided to which domain you will add a new user navigate to Users and Groups section All Users Add user imagesusersinazurepng Create the user configure all fields User name is the identifier that the user enters to sign in to Azure AD If you see the password during the user configuration it means that you are creating the School or Working account in your domain imagescreateazureuserpng Copy your initial password You will need it later The initial password have to be changed on your first logon Then we need to assign a right subscription to this new user Go to subscriptions Select one that you decided to use for your Azure VM imagessubscriptionspng Then Access Control IAM Add the new user to a certain subscription Adding a new useraddnewuser imagesazureiampng Select a role with the certain rights that enough for Azure VM creation imagesazureiamrolepng Once you selected the role select the user that you recently created Then you need to log out and log in by using the credentials for newly created user and change the initial password Eventually you need to create your Azure VM account under your MBS control panel During the signing in you should enter the credentials for user that have been created during the previous steps imagesazurevmaccountpng"},{"title":"Unexpected backup or restore plan termination due to insufficient system resources","kbid":1076,"author":"Robert","href":"/kb1076","content":" Problem Sometimes you may encounter a situation wherein a backup or restore plan fails due to insufficient system resources Suggestions and Resolutions Surely there may be many different reasons as to why that happens However it is often the case that the excessive number of utilized threads is to blame One workaround for that issue is to reduce the number of threads in the settings To do that click Settings Under Applications click Advanced Settings and then reduce the number in the Max thread count text field imagesreduceThreadspng Alternatively you can perform the same procedure using our command line interface Simply execute the following commands in the terminal cd ApplicationsCloudBerry BackupappContentsMacOS cbb option set tc v 3 where 3 is the number of threads"},{"title":"Silent install macOS and Linux builds","kbid":1077,"author":"Eugene","href":"/kb1077","content":" Problem Sometimes you may need to install a product without any user interaction CloudBerry Backup for Windows supports this mode with the following flag CloudBerryBackupBuildexe S For macOS and Linux builds this is not the case Suggestions and Resolutions macOS First mount the CloudBerryBackupdmg image using hdiutil sudo hdiutil attach CloudBerryBackupdmg Once the image mounted to VolumesImageName the package can be installed sudo installer package VolumesImageNameImageNamepkg target Change ImageName to yours accordingly Once installed we can detach imagage sudo hdiutil detach VolumesImageName Linux Linux build is installed using package manager eg dpkg rpm etc So you may need to check environment variables for those package managers to ignore questions during installation For example for Debian family the following should disable questions and give us unattended installation export DEBIANFRONTENDnoninteractive export DEBIANPRIORITYcritical "},{"title":"VMWare permission for CloudBerry Backup","kbid":1078,"author":"Stanislav","href":"/kb1078","content":" Problem You may want to use a dedicated user to run CloudBerry Backup with your VMWare infrastucture Suggestions and Resolutions Thats an explicit list of vCenter permissions to backup and restore VMs using CloudBerry Backup VM Edition "},{"title":"Retrieving list of backups performed for specific database","kbid":1079,"author":"Stanislav","href":"/kb1079","content":" Problem When creating your backup strategy with Cloudberry Backup sometines you need to analyze backup perfomance Suggestions and Resolutions 1 Start MS SQL management studio 2 Create a new script 3 Select the database to run against 4 Instert the following script and execute it SELECT sdatabasename mphysicaldevicename CASTCASTsbackupsize 1000000 AS INT AS VARCHAR14 MB AS bkSize CASTDATEDIFFsecond sbackupstartdate sbackupfinishdate AS VARCHAR4 Seconds TimeTaken sbackupstartdate CASTsfirstlsn AS VARCHAR50 AS firstlsn CASTslastlsn AS VARCHAR50 AS lastlsn CASE stype WHEN D THEN Full WHEN I THEN Differential WHEN L THEN Transaction Log END AS BackupType sservername srecoverymodel FROM msdbdbobackupset s INNER JOIN msdbdbobackupmediafamily m ON smediasetid mmediasetid WHERE sdatabasename DBNAME ORDER BY backupstartdate DESC backupfinishdate GO Reference Pinal Dave httpsblogsqlauthoritycom"},{"title":"Automating installation and removal of Cloudberry Drive for AWS EC2 AutoScaling groups","kbid":1080,"author":"Stanislav","href":"/kb1080","content":" Problem If you have EC2 AutoScaling group and want to use CloudBerrry Drive inside each managed instance and have a license key for multiple CB Drive installations you may want to automate CB Drive installation to newly created instances and properly reclaim they key when terminating them Suggestions and Resolutions The suggested approach is to use EC2 LifeCycle hooks that will execute routines on instances and wait for completion LifeCycle hooks sends AWS SNS notification and AWS Lambda function is triggered to perform appropriate action Lambda function in turn executes a PowerShell script inside the instance You can store your PowerShell scripts and CB Drive instance in any HTTP location In our example they are stored in S3 httpss3useast2amazonawscomcbdrive please replace that path with your own location CBDrive licensing information is stored as AWS SMS parameter Preparing the enironment You need to have an AutoScaling group with 0 instances running If you are going to add automation to the existing ASG keep in mind that the drive will not be installed into running instances You will need to create ASG on your own that topic is not covered in this article In the code below ASG name will be CBDriveASG You will need to change it to your name Configuring the environment Create SNS topic named CBDrive aws sns createtopic name CBDrive The output should look like TopicArn arnawssnsuseast21234567890CBDrive Remember the ARN for the topic you will need it later Create IAM role CBDriveHooksRole that will allow LifeCycle hooks to publish messages to SNS topic CBDrive First create a file AutoscaleAssumeRolejson and enter the following content This will allow AutoScaling to assume roles IAM roles Version 20121017 Statement Sid Effect Allow Principal Service autoscalingamazonawscom Action stsAssumeRole Then create a policy file CBDrivejson and allow publishing to SNS topic CBDrive You will need to change ARN in the example to the ARN of your topic Version 20121017 Statement Effect Allow Resource Action snsPublish Finally create the IAM Role aws iam createrole rolename CBDriveHooksRole assumerolepolicydocument fileAutoscaleAssumeRolejson Output Role AssumeRolePolicyDocument Version 20121017 Statement Action stsAssumeRole Principal Service autoscalingamazonawscom Effect Allow Sid RoleId AROAI16U3N2KRKUOCTJ4C CreateDate 20170713T155609043Z RoleName CBDriveHooksRole Path Arn arnawsiam1234567890roleCBDriveHooksRole And attach the inline policy aws iam putrolepolicy rolename CBDriveHooksRole policyname AllowPublishCBDriveTopic policydocument fileCBDrivejson No output is expected Create IAM role that allow execution for Lambda functions Create a file LambdaRolejson Version 20121017 Statement Sid Effect Allow Principal Service lambdaamazonawscom Action stsAssumeRole And the policy file LambdaPolicyjson Version 20121017 Statement Effect Allow Resource Action logs ssm autoscalingCompleteLifecycleAction Action logsCreateLogGroup logsCreateLogStream logsPutLogEvents Resource arnawslogs Effect Allow Create the IAM role aws iam createrole rolename LambdaCBDRole assumerolepolicydocument fileLambdaRolejson Output Role AssumeRolePolicyDocument Version 20121017 Statement Action stsAssumeRole Principal Service lambdaamazonawscom Effect Allow Sid RoleId AROAIZWVMVZR36MN9OXZS CreateDate 20170713T160052378Z RoleName LambdaCBDRole Path Arn arnawsiam1234567890roleLambdaCBDRole And attach the policy aws iam putrolepolicy rolename LambdaCBDRole policyname ExecuteCBDriveAutomation policydocument fileLambdaPolicyjson No output is expected Put lifecycle hooks For pushing CB Drive into newly deployed EC2 instance aws autoscaling putlifecyclehook lifecyclehookname InstallCBDrive autoscalinggroupname CBDriveASG lifecycletransition autoscalingEC2INSTANCELAUNCHING rolearn arnawsiam1234567890roleCBDriveHooksRole notificationtargetarn arnawssnsuseast21234567890CBDrive heartbeattimeout 1800 defaultresult CONTINUE And for reclaiming the license aws autoscaling putlifecyclehook lifecyclehookname RemoveCBDrive autoscalinggroupname CBDriveASG lifecycletransition autoscalingEC2INSTANCETERMINATING rolearn arnawsiam1234567890roleCBDriveHooksRole notificationtargetarn arnawssnsuseast21234567890CBDrive heartbeattimeout 1800 defaultresult CONTINUE Create the Lambda function Heres the code of our Lambda function import boto3 import time import json import logging logger logginggetLogger loggersetLevelloggingINFO def getParameterparamname Create the SSM Client ssm boto3clientssm Get the requested parameter response ssmgetparameters Names paramname WithDecryptionFalse Store the credentials in a variable credentials responseParameters0Value return credentials def scaleUpintInstanceId ssmClient boto3clientssm license dictitemsplit for item in getParameterCBBDriveLicensesplit ssmCommand ssmClientsendcommand InstanceIds intInstanceId DocumentName AWSRunPowerShellScript TimeoutSeconds 240 Comment Install Cloudberry Drive Parameters commands InvokeWebRequest httpss3useast2amazonawscomcbdriveinstallDriveps1 outfile cinstallDriveps1CinstallDriveps1 license licenselicense email licenseemail poll SSM until EC2 Run Command completes status Pending while status Pending or status InProgress timesleep3 status ssmClientlistcommandsCommandIdssmCommandCommandCommandIdCommands0Status ifstatus Success loggerinfoFailed to install CB Dirve with status status else loggerinfoCB Drive installed return def scaleDownintInstanceId ssmClient boto3clientssm ssmCommand ssmClientsendcommand InstanceIds intInstanceId DocumentName AWSRunPowerShellScript TimeoutSeconds 240 Comment Remove Cloudberry Drive Parameters commands InvokeWebRequest httpss3useast2amazonawscomcbdriveremoveDriveps1 outfile cremoveDriveps1CremoveDriveps1 poll SSM until EC2 Run Command completes status Pending while status Pending or status InProgress timesleep3 status ssmClientlistcommandsCommandIdssmCommandCommandCommandIdCommands0Status ifstatus Success loggerinfoFailed to remove CB Drive with status status else loggerinfoCB Drive removed return The lambdahandler Python function gets called when you run your AWS Lambda function def lambdahandlerevent context s3Client boto3clients3 snsClient boto3clientsns asClient boto3clientautoscaling ecClient boto3clientec2 message jsonloadseventuRecords0uSnsuMessage loggerinfojsondumpsevent if messageLifecycleTransition autoscalingEC2INSTANCETERMINATING scaleDownmessageEC2InstanceId elif messageLifecycleTransition autoscalingEC2INSTANCELAUNCHING timesleep60 scaleUpmessageEC2InstanceId else loggerinfoUnknow state eventType response asClientcompletelifecycleaction LifecycleHookNamemessageLifecycleHookName AutoScalingGroupNamemessageAutoScalingGroupName LifecycleActionTokenmessageLifecycleActionToken LifecycleActionResultCONTINUE InstanceIdmessageEC2InstanceId return You will need to save it to file ManageCBDrivepy and compress into ManageCBDrivezip archive Then create the Lambda function in AWS aws lambda createfunction functionname ManageCBDrive zipfile filebManageCBDrive10zip runtime python36 role arnawsiam1234567890roleLambdaCBDRole handler ManageCBDrivelambdahandler timeout 300 Output TracingConfig Mode PassThrough CodeSha256 HuG0UIv3s2QzX4RB1Hokq5tn38EZV3LzVHCMycXb9o FunctionName ManageCBDrive CodeSize 1349 MemorySize 128 FunctionArn arnawslambdauseast21234567890functionManageCBDrive Version LATEST Role arnawsiam1234567890roleLambdaCBDRole Timeout 300 LastModified 20170713T1656077470000 Handler ManageCBDrivelambdahandler Runtime python36 Description Subscribe the Lambda function to the SNS topic aws sns subscribe protocol lambda topicarn arnawssnsuswest21234567890CBDrive notificationendpoint arnawslambdauswest21234567890functionManageCBDrive Output SubscriptionArn arnawssnsuseast2988585708477CBDrive7527c5b4528247b7bed338943a78f64c Grant permissions on the lambda function to the SNS topic aws lambda addpermission functionname ManageCBDrive statementid 1 action lambdaInvokeFunction principal snsamazonawscom sourcearn arnawssnsuswest21234567890CBDrive Output Statement Sid1Resourcearnawslambdauseast21234567890functionManageCBDriveEffectAllowPrincipalServicesnsamazonawscomActionlambdaInvokeFunctionConditionArnLikeAWSSourceArnarnawssnsuseast21234567890CBDrive Create AWS SMS parameter and store licensing information there aws ssm putparameter name CBBDriveLicense type String value licenseXXXXXXXXXXXXXXXXXXXXXXXXXXXXemailyourameyourdomaincom Upload PowerShell script and CB Drive distro to your HTTP share installDriveps1 param Parameter MandatoryTruestringlicense Parameter MandatoryTruestringemail NewItem ItemType Directory Force Path cbootstrap urlhttps3amazonawscomcbcurrentreleasesDrivesetupexe outputcbootstrapsetupexe InvokeWebRequest url outfile output installcommandoutput installarguments S startprocess FilePath installcommand ArgumentList installarguments Wait activatecommandCProgram FilesCloudBerryLabCloudBerry Drivecbdexe activatearguments activatelicense k license e email StartProcess FilePath activatecommand ArgumentList activatearguments Wait RemoveItem Path output removeDriveps1 releasecommandcProgram FilesCloudBerryLabCloudBerry Drivecbdexe releasearguments silent releaselicense startprocess FilePath releasecommand ArgumentList releasearguments Wait uninstallcommandcProgram FilesCloudBerryLabCloudBerry Driveuninstexe uninstallarguments S StartProcess FilePath uninstallcommand ArgumentList uninstallarguments Wait RemoveItem Path CremoveDriveps1 "},{"title":"Missing driver on WinPE while trying to restore with bootable USB","kbid":1081,"author":"Anton","href":"/kb1081","content":" Problem When trying to restore imagebased backup via bootable USB device you may receive an error A connection to the deployment share couldnt not be made The following networking device did not have a driver installed This may be a cause of network device driver absence or some failure during drivers import imageskb108110811png Suggestions and Resolutions Option 1 The easiest way to resolve issue is to burn new bootable USB and add necessary drivers on the preburn configuration wizard imageskb108110812png You can do it from the PC you were backing up or from any other Windows PC Option 2 In case you are not able to burn new bootable USB following procedure will help you to add drivers without third party tools Create temporary folder on your machine CTemp Copy Bootwim file from ESOURCESBOOTWIM bootable USB to CTemp Copy drivers to CTempmydrivers imageskb108110813png Create cloudremount folder imageskb108110814png Mount the wim file Dism MountImage ImageFileCTempBootwim index1 MountDirCTempcloudremount Add your driver yourDriverNameinf to cloudremount folder Dism AddDriver ImageCTempcloudremount DriverCTempmydriversyourDriverNameinf Check if the driver appeared in cloudremount folder installed drivers should be listed Dism GetDrivers ImageCTempcloudremount Unmount image and save changes Dism UnmountWim MountDirCTempcloudremount commit And thats it This is how it should looks in command line imageskb108110815png"},{"title":"The remote name could not be resolved: mspbackups.com","kbid":1082,"author":"Anton","href":"/kb1082","content":" Problem When trying to restore imagebased backup via bootable USB device once you will boot and try to login CloudBerry agent you may face with an error The remote name could not be resolved mspbackupscom imageskb108210821png Suggestions and Resolutions This error may occur in case of IP address configuration absence for example in case of machine is in a network without DHCP server As a solution you can configure a static IP address via command prompt Boot from CloudBerry USB go Tools and select Command Prompt imageskb108210822png Check an IP address with command netsh interface ipv4 show config imageskb108210823png Once youll execute a command check the name of a network interface you are going to configure eg Local Area Connection Assign a static IP address with the following command netsh interface ipv4 set address nameYOUR INTERFACE NAME static IPADDRESS SUBNETMASK GATEWAY imageskb108210824png In case of DNS is needed use the command netsh interface ipv4 set dns nameYOUR INTERFACE NAME static DNSSERVER Exit command prompt and select Bare Metal Recovery it may take some time to launch CloudBerry agent software"},{"title":"Warning. One or more backup paths do not exist","kbid":1083,"author":"Alex","href":"/kb1083","content":" Problem Your backup job run as scheduled But by some reasons you received the notification with the message Warning One or more backup paths dont exist Suggestions and Resolutions 1 First reason the human factor You set up the backup plan select filesfolders that you want to backup on the source step saved backup plan and go ahead But then by some reasons some directoriesfoldersfiles have been deleted by someone And just dont exist Therefore the software can not find them 2 Second reason your permission settings Users might not backup only local files Documents that located on network shares can be in the list So make sure that the account under which the service CloudBerry backup service is up and running andor the PC itself have enough rights to backup files that selected on the source step By default CloudBerry backup service is up and running under Local System Account Commonly this account doesnt have right permissions for backing up files Local system account is a computer record Therefore if you go to the filefolder security options you can add your computer there and rerun backup then How to determine which paths are no longer exist check your diagnostic information log files Probably should be switched in High level in the agent on tab History filter by files and in the list youll find which files have been skipped liaise with our support team or solutions architects"},{"title":"CloudBerry Remote Assistant How do I generate an invitation link?","kbid":1084,"author":"Harry","href":"/kb1084","content":" Problem You tried to establish the connection but you cant find the link generation tool Suggestions and Resolutions 1 You try to remote in and want to share the link with your partner imageskb1084RA4png 2 You need assistance and you want to generate the invitation link imageskb1084RA5png"},{"title":"CloudBerry Remote Assistant Disconnect details io client disconnect","kbid":1085,"author":"Harry","href":"/kb1085","content":" Problem You tried to establish the connection but you get Disconnect details io client disconnect error imageskb1085RA1png Suggestions and Resolutions 1 Please check if the destination PC is turned on and has CloudBerry Remote Assistant launched 2 Please check the computer ID and password on the destination PC"},{"title":"CloudBerry Remote Assistant Connection request failed client connection failed","kbid":1086,"author":"Harry","href":"/kb1086","content":" Problem You tried to establish the connection but the attempt resulted in Connection request failed client connection failed error imageskb1084RA2png Suggestions and Resolutions This error message means that your partner has declined the connection when prompted"},{"title":"CloudBerry Remote Assistant Connection request failed: client connection failed","kbid":1087,"author":"Harry","href":"/kb1087","content":" Problem You tried to establish the connection but the attempt resulted in Secure connection request expected Public encryption key is missing or invalid error imageskb1087RA3png Suggestions and Resolutions This error message means that encryption has not been configured correctly between these two clients Please refer to the following article on how to establish encrypted connection httpswwwcloudberrylabcomblogsaferemotedesktopwithcloudberryremoteassistant"}]